package com.sundogsoftware.spark

import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.spark.sql._
import org.apache.log4j._

import org.apache.spark.ml.regression.LinearRegression
import org.apache.spark.sql.types._
import org.apache.spark.ml.linalg.Vectors

object LinearRegressionDataFrame {
  
  
  /** Our main function where the action happens */
  def main(args: Array[String]) {
    // Set the log level to only print errors
    Logger.getLogger("org").setLevel(Level.ERROR)
    
    // Use new SparkSession interface in Spark 2.0
    val spark = SparkSession
      .builder
      .appName("LinearRegressionDF")
      .master("local[*]")
      .config("spark.sql.warehouse.dir", "file:///C:/temp") // Necessary to work around a Windows bug in Spark 2.0.0; omit if you're not on Windows.
      .getOrCreate()
      
    // Load up our page speed / amount spent data in the format required by MLLib
    // (which is label, vector of features)
      
    // In machine learning lingo, "label" is just the value you're trying to predict, and
    // "feature" is the data you are given to make a prediction with. So in this example
    // the "labels" are the first column of our data, and "features" are the second column.
    // You can have more than one "feature" which is why a vector is required.
    val inputLines = spark.sparkContext.textFile("../regression.txt")
    val data = inputLines.map(_.split(",")).map(x => (x(0).toDouble, Vectors.dense(x(1).toDouble))) //label and features dense factor 1 0r 0
    
    // Convert this RDD to a DataFrame
    import spark.implicits._
    val colNames = Seq("label", "features")
    val df = data.toDF(colNames: _*) // _*we are passing list of stuff
    
    // Note, there are lots of cases where you can avoid going from an RDD to a DataFrame.
    // Perhaps you're importing data from a real database. Or you are using structured streaming
    // to get your data.
     
    // Let's split our data into training data and testing data
    val trainTest = df.randomSplit(Array(0.5, 0.5))
    val trainingDF = trainTest(0)
    val testDF = trainTest(1)
    
    // Now create our linear regression model
    val lir = new LinearRegression()
      .setRegParam(0.3) // regularization 
      .setElasticNetParam(0.8) // elastic net mixing
      .setMaxIter(100) // max iterations
      .setTol(1E-6) // convergence tolerance
    
    // Train the model using our training data
    val model = lir.fit(trainingDF)
    
    // Now see if we can predict values in our test data.
    // Generate predictions using our linear regression model for all features in our 
    // test dataframe:
    val fullPredictions = model.transform(testDF).cache()
    
    // This basically adds a "prediction" column to our testDF dataframe.
    
    // Extract the predictions and the "known" correct labels.
    val predictionAndLabel = fullPredictions.select("prediction", "label").rdd.map(x => (x.getDouble(0), x.getDouble(1))) 
    
    // Print out the predicted and actual values for each point
    for (prediction <- predictionAndLabel) {
      println(prediction)
    }
    
    // Stop the session
    spark.stop()

  }
}
===================================================================================
(-1.8235627330720618,-2.6)
(-2.652056713500816,-3.74)
(-1.653615249907189,-2.43)
(-1.8589684587314101,-2.36)
(-1.5190734924016647,-2.22)
(-1.5473980729291437,-2.27)
(-1.4765866216104466,-2.14)
(-1.3916128800280103,-2.09)
(-1.4836677667423164,-1.98)
(-1.441180895951098,-2.07)
(-1.3774505897642708,-1.91)
(-1.4270186056873588,-2.0)
(-1.3420448641049223,-1.84)
(-1.3986940251598798,-1.96)
(-1.186259671203789,-1.83)
(-1.370369444632401,-1.94)
(-1.2712334127862255,-1.8)
(-1.3986940251598798,-1.94)
(-1.2641522676543557,-1.7)
(-1.2924768481818345,-1.91)
(-1.1083670747532224,-1.68)
(-1.3137202835774435,-1.91)
(-1.207503106599398,-1.68)
(-1.3349637189730525,-1.88)
(-1.0871236393576131,-1.6)
(-1.1720973809400494,-1.74)
(-1.1225293650169617,-1.59)
(-1.0304744783026556,-1.67)
(-1.16501623580818,-1.58)
(-1.1508539455444404,-1.65)
(-1.0517179136982646,-1.54)
(-1.2995579933137043,-1.64)
(-0.9879876075114372,-1.5)
(-1.1508539455444404,-1.6)
(-1.0729613490938739,-1.45)
(-1.143772800412571,-1.59)
(-1.044636768566395,-1.42)
(-1.186259671203789,-1.53)
(-0.995068752643307,-1.46)
(-0.8676081402696525,-1.41)
(-1.1225293650169617,-1.42)
(-1.0304744783026556,-1.4)
(-0.9313384464564798,-1.4)
(-1.016312188038916,-1.39)
(-0.8817704305333919,-1.37)
(-0.8676081402696525,-1.38)
(-0.8038778340828251,-1.3)
(-0.8817704305333919,-1.36)
(-0.832202414610304,-1.3)
(-0.9667441721158283,-1.36)
(-1.0233933331707858,-1.3)
(-0.8392835597421736,-1.35)
(-0.8038778340828251,-1.29)
(-0.8746892854015221,-1.35)
(-1.0375556234345253,-1.29)
(-1.0092310429070466,-1.35)
(-0.9384195915883495,-1.34)
(-0.7826343986872162,-1.3)
(-0.8463647048740434,-1.27)
(-0.8463647048740434,-1.25)
(-0.8676081402696525,-1.25)
(-0.7684721084234767,-1.23)
(-0.7897155438190858,-1.16)
(-0.7330663827641282,-1.09)
(-0.7755532535553464,-1.08)
(-0.619768060654213,-1.03)
(-0.5914434801267342,-1.01)
(-0.761390963291607,-1.01)
(-0.8251212694784342,-1.01)
(-0.7047418022366494,-1.0)
(-0.761390963291607,-0.99)
(-0.6339303509179525,-0.98)
(-0.5560377544673858,-0.97)
(-0.7330663827641282,-0.97)
(-0.6764172217091706,-0.95)
(-0.6410114960498221,-0.93)
(-0.7472286730278677,-0.93)
(-0.7189040925003888,-0.92)
(-0.6056057703904736,-0.91)
(-0.548956609335516,-0.9)
(-0.6268492057860827,-0.9)
(-0.7330663827641282,-0.82)
(-0.5135508836761675,-0.81)
(-0.853445850005913,-1.26)
(-0.5843623349948645,-0.81)
(-0.8463647048740434,-1.22)
(-0.5631188995992554,-0.8)
(-0.7826343986872162,-1.2)
(-0.6622549314454311,-0.78)
(-0.8463647048740434,-1.2)
(-0.6693360765773009,-0.78)
(-0.8746892854015221,-1.17)
(-0.6622549314454311,-0.77)
(-0.8817704305333919,-1.17)
(-0.6126869155223433,-0.76)
(-0.8817704305333919,-1.16)
(-0.45690172262121,-0.75)
(-0.8109589792146948,-1.14)
(-0.548956609335516,-0.75)
(-0.8676081402696525,-1.11)
(-0.5631188995992554,-0.75)
(-0.761390963291607,-1.1)
(-0.5914434801267342,-0.75)
(-0.7472286730278677,-1.09)
(-0.47814515801681906,-0.74)
(-0.7897155438190858,-1.08)
(-0.47106401288494937,-0.73)
(-0.7259852376322585,-1.07)
(-0.5206320288080373,-0.73)
(-0.7543098181597373,-1.03)
(-0.41441485182999177,-0.72)
(-0.5702000447311252,-0.95)
(-0.5914434801267342,-0.72)
(-0.7047418022366494,-0.94)
(-0.386090271302513,-0.7)
(-0.7189040925003888,-0.94)
(-0.5418754642036463,-0.7)
(-0.6410114960498221,-0.91)
(-0.43565828722560085,-0.64)
(-0.5418754642036463,-0.88)
(-0.41441485182999177,-0.62)
(-0.6410114960498221,-0.85)
(-0.44273943235747054,-0.61)
(-0.5843623349948645,-0.84)
(-0.24446736866511898,-0.6)
(-0.6268492057860827,-0.84)
(-0.3790091261706433,-0.59)
(-0.4923074482805584,-0.82)
(-0.42149599696186146,-0.59)
(-0.5135508836761675,-0.8)
(-0.3365222553794251,-0.55)
(-0.4639828677530797,-0.78)
(-0.2798730943244675,-0.54)
(-0.5702000447311252,-0.78)
(-0.44273943235747054,-0.54)
(-0.4639828677530797,-0.76)
(-0.2373862235332493,-0.48)
(-0.5914434801267342,-0.76)
(-0.40025256156625233,-0.48)
(-0.6551737863135615,-0.74)
(-0.32944111024755535,-0.47)
(-0.386090271302513,-0.71)
(-0.3011165297200766,-0.44)
(-0.619768060654213,-0.71)
(-0.3506845456431645,-0.44)
(-0.5277131739399069,-0.7)
(-0.18781820761016144,-0.41)
(-0.47106401288494937,-0.67)
(-0.22322393326950993,-0.41)
(-0.3790091261706433,-0.65)
(-0.20906164300577051,-0.4)
(-0.40025256156625233,-0.65)
(-0.3223599651156857,-0.4)
(-0.4498205774893403,-0.65)
(-0.3931714164343827,-0.4)
(-0.407333706698122,-0.62)
(-0.11700675629146445,-0.38)
(-0.3931714164343827,-0.6)
(-0.2586296589288584,-0.37)
(-0.3719279810387736,-0.52)
(-0.30819767485194627,-0.37)
(-0.4852263031486887,-0.52)
(-0.3365222553794251,-0.36)
(-0.2373862235332493,-0.51)
(-0.17365591734642202,-0.35)
(-0.3931714164343827,-0.5)
(-0.2798730943244675,-0.35)
(-0.30819767485194627,-0.49)
(-0.2940353845882069,-0.35)
(-0.30819767485194627,-0.49)
(-0.22322393326950993,-0.34)
(-0.386090271302513,-0.48)
(-0.25154851379698867,-0.32)
(-0.2727919491925978,-0.43)
(-0.14533133681894322,-0.31)
(-0.315278819983816,-0.42)
(-0.10992561115959476,-0.3)
(-0.3577656907750342,-0.41)
(-0.2798730943244675,-0.3)
(-0.18781820761016144,-0.39)
(-0.2869542394563372,-0.29)
(-0.17365591734642202,-0.34)
(-0.3790091261706433,-0.26)
(-0.2727919491925978,-0.33)
(-0.2019804978739008,-0.25)
(-0.14533133681894322,-0.32)
(-0.2727919491925978,-0.25)
(-0.20906164300577051,-0.31)
(-0.09576332089585536,-0.21)
(-0.2161427881376402,-0.3)
(-0.19489935274203113,-0.2)
(-0.2940353845882069,-0.3)
(-0.23030507840137962,-0.2)
(-0.2373862235332493,-0.29)
(-0.08160103063211596,-0.19)
(-0.2019804978739008,-0.28)
(-0.10992561115959476,-0.19)
(-0.07451988550024626,-0.26)
(-0.10992561115959476,-0.19)
(-0.15949362708268264,-0.26)
(-0.060357595236506856,-0.18)
(-0.15241248195081292,-0.25)
(-0.010789579313418975,-0.16)
(-0.16657477221455233,-0.24)
(-0.18781820761016144,-0.24)
(-0.16657477221455233,-0.23)
(-0.2019804978739008,-0.22)
(-0.07451988550024626,-0.21)
(-0.25154851379698867,-0.21)
(-0.2019804978739008,-0.19)
(-0.09576332089585536,-0.18)
(-0.13116904655520384,-0.17)
(-0.09576332089585536,-0.16)
(-0.15241248195081292,-0.16)
(-0.07451988550024626,-0.11)
(-0.15241248195081292,-0.14)
(-0.04619530497276747,-0.1)
(-0.2657108040607281,-0.14)
(-0.08868217576398565,-0.1)
(-0.10992561115959476,-0.13)
(-0.06743874036837656,-0.09)
(-0.18781820761016144,-0.12)
(0.0671030171371477,-0.07)
(-0.024951869577158375,-0.11)
(0.01045385608219012,-0.07)
(-0.06743874036837656,-0.1)
(0.04585958174153861,-0.05)
(-0.18073706247829172,-0.1)
(0.01753500121405982,-0.05)
(-0.0037084341815492774,-0.09)
(-0.03911415984089777,-0.05)
(-0.04619530497276747,-0.07)
(0.0954275976646265,-0.04)
(-0.010789579313418975,-0.05)
(-0.0037084341815492774,-0.04)
(-0.15949362708268264,-0.04)
(0.0812653074008871,-0.02)
(0.0883464525327568,-0.02)
(-0.13116904655520384,-0.01)
(0.0812653074008871,-0.02)
(-0.14533133681894322,-0.01)
(0.01045385608219012,-0.02)
(0.05294072687340831,0.0)
(-0.09576332089585536,-0.02)
(0.04585958174153861,0.0)
(-0.060357595236506856,-0.01)
(-0.017870724445288675,-0.0)
(0.04585958174153861,-0.0)
(0.04585958174153861,0.01)
(0.1095898879283659,0.01)
(0.03877843660966891,0.02)
(0.0741841622690174,0.03)
(-0.0037084341815492774,0.02)
(-0.010789579313418975,0.03)
(0.03169729147779922,0.03)
(-0.0037084341815492774,0.04)
(0.0033727109503204214,0.05)
(0.05294072687340831,0.05)
(0.1025087427964962,0.06)
(0.05294072687340831,0.07)
(0.06002187200527801,0.08)
(-0.060357595236506856,0.07)
(0.1025087427964962,0.09)
(-0.024951869577158375,0.08)
(0.0883464525327568,0.1)
(0.1166710330602356,0.09)
(-0.13825019168707353,0.1)
(0.0812653074008871,0.09)
(0.1025087427964962,0.11)
(0.01753500121405982,0.09)
(0.0671030171371477,0.11)
(0.05294072687340831,0.11)
(-0.03203301470902807,0.11)
(0.1662390489833235,0.12)
(0.01045385608219012,0.11)
(0.22288821003828108,0.14)
(0.15915790385145379,0.19)
(0.0671030171371477,0.19)
(0.130833323323975,0.21)
(0.15915790385145379,0.24)
(0.20872591977454166,0.26)
(0.1945636295108023,0.29)
(0.1662390489833235,0.29)
(0.1449956135877144,0.32)
(0.1237521781921053,0.33)
(0.37159225780754473,0.34)
(0.35742996754380535,0.35)
(0.0812653074008871,0.13)
(0.30786195162071744,0.36)
(0.1025087427964962,0.14)
(0.3361865321481962,0.37)
(0.0812653074008871,0.14)
(0.37159225780754473,0.38)
(0.25121279056575985,0.15)
(0.3291053870163266,0.38)
(0.1449956135877144,0.15)
(0.2795373710932387,0.38)
(0.1520767587195841,0.16)
(0.2370505003020205,0.38)
(0.1449956135877144,0.16)
(0.18748248437893258,0.38)
(0.04585958174153861,0.16)
(0.3291053870163266,0.4)
(0.18748248437893258,0.2)
(0.39283569320315387,0.41)
(0.1804013392470629,0.21)
(0.31494309675258714,0.41)
(0.1662390489833235,0.21)
(0.25829393569762954,0.42)
(0.130833323323975,0.21)
(0.46364714452185085,0.45)
(0.22288821003828108,0.22)
(0.4494848542581114,0.45)
(0.1095898879283659,0.24)
(0.39991683833502356,0.45)
(0.3361865321481962,0.45)
(0.1733201941151932,0.25)
(0.22288821003828108,0.45)
(0.130833323323975,0.25)
(0.24413164543389018,0.47)
(0.24413164543389018,0.26)
(0.201644774642672,0.26)
(0.1449956135877144,0.26)
(0.28661851622510837,0.29)
(0.1804013392470629,0.29)
(0.1520767587195841,0.29)
(0.1166710330602356,0.29)
(0.21580706490641138,0.31)
(0.25829393569762954,0.34)
(0.3361865321481962,0.36)
(0.25829393569762954,0.37)
(0.2370505003020205,0.37)
(0.2795373710932387,0.4)
(0.2795373710932387,0.41)
(0.30786195162071744,0.42)
(0.46364714452185085,0.5)
(0.3361865321481962,0.43)
(0.22288821003828108,0.51)
(0.30078080648884775,0.43)
(0.47072828965372054,0.55)
(0.31494309675258714,0.44)
(0.49197172504932957,0.6)
(0.2653750808294993,0.44)
(0.46364714452185085,0.63)
(0.31494309675258714,0.46)
(0.34326767728006596,0.64)
(0.30786195162071744,0.46)
(0.45656599938998116,0.65)
(0.45656599938998116,0.49)
(0.42824141886250233,0.65)
(0.2653750808294993,0.49)
(0.5981889020273751,0.68)
(0.4424037091262417,0.5)
(0.5273774507086781,0.68)
(0.4424037091262417,0.51)
(0.435322563994372,0.68)
(0.36451111267567504,0.51)
(0.5202963055768084,0.69)
(0.39991683833502356,0.53)
(0.42824141886250233,0.69)
(0.35034882241193566,0.53)
(0.5698643214998963,0.73)
(0.3361865321481962,0.53)
(0.49905287018119926,0.73)
(0.36451111267567504,0.54)
(0.5557020312361569,0.74)
(0.435322563994372,0.58)
(0.42824141886250233,0.74)
(0.4069979834668932,0.58)
(0.6052700471592448,0.75)
(0.34326767728006596,0.61)
(0.39991683833502356,0.63)
(0.576945466631766,0.78)
(0.49905287018119926,0.64)
(0.5698643214998963,0.78)
(0.3857545480712842,0.65)
(0.506134015313069,0.66)
(0.5557020312361569,0.78)
(0.5202963055768084,0.67)
(0.49197172504932957,0.78)
(0.5202963055768084,0.69)
(0.576945466631766,0.81)
(0.4494848542581114,0.69)
(0.5202963055768084,0.82)
(0.6335946276867236,0.7)
(0.42116027373063264,0.84)
(0.39283569320315387,0.7)
(0.5911077568955053,0.89)
(0.6052700471592448,0.71)
(0.6831626436098115,0.9)
(0.647756917950463,0.72)
(0.6406757728185933,0.9)
(0.576945466631766,0.72)
(0.6760814984779417,0.91)
(0.45656599938998116,0.74)
(0.6335946276867236,0.95)
(0.4140791285987629,0.74)
(0.5981889020273751,0.97)
(0.5698643214998963,0.76)
(0.8177044011153357,0.98)
(0.7539740949285085,0.98)
(0.7114872241372903,0.99)
(0.6265134825548538,0.99)
(0.7468929497966388,1.02)
(0.7681363851922479,1.05)
(0.71856836926916,1.05)
(0.6265134825548538,1.05)
(0.5486208861042872,0.76)
(0.789379820587857,1.08)
(0.48489057991745993,0.77)
(0.789379820587857,1.09)
(0.5627831763680267,0.78)
(0.8177044011153357,1.16)
(0.5132151604449386,0.79)
(0.9947330294120781,1.17)
(0.46364714452185085,0.81)
(0.8460289816428145,1.19)
(0.576945466631766,0.83)
(0.9310027232252509,1.26)
(0.5840266117636357,0.84)
(0.8531101267746842,1.27)
(0.5202963055768084,0.84)
(0.9097592878296419,1.31)
(0.6619192082142024,0.9)
(0.9593273037527298,1.35)
(0.6194323374229842,0.9)
(1.0372199002032962,1.36)
(0.5911077568955053,0.9)
(0.9451650134889904,1.38)
(0.6052700471592448,0.93)
(1.1292747869176023,1.4)
(0.5627831763680267,0.93)
(0.881434707302163,1.5)
(0.71856836926916,0.95)
(1.2425731090275176,1.53)
(0.5627831763680267,0.95)
(1.0301387550714265,1.53)
(0.7681363851922479,0.96)
(1.115112496653863,1.65)
(0.5981889020273751,0.96)
(1.17884280284069,1.69)
(0.6548380630823327,0.97)
(1.1080313515219933,1.74)
(0.6052700471592448,0.97)
(1.2284108187637781,1.76)
(0.647756917950463,0.98)
(1.3771148665330417,1.78)
(0.669000353346072,0.99)
(1.2000862382362993,1.8)
(0.8177044011153357,1.05)
(1.306303415214345,1.82)
(0.789379820587857,1.06)
(1.2496542541593871,1.82)
(0.7044060790054205,1.1)
(1.327546850609954,1.86)
(0.9168404329615115,1.11)
(1.327546850609954,1.86)
(0.8531101267746842,1.11)
(1.5753869302253936,2.08)
(0.8247855462472053,1.11)
(1.7807401390496145,2.67)
(0.7822986754559873,1.12)
(2.056904799192533,2.71)
(0.8601912719065539,1.14)
(0.9168404329615115,1.18)
(0.8318666913790751,1.18)
(0.8601912719065539,1.19)
(0.789379820587857,1.27)
(1.0513821904670357,1.39)
(0.9310027232252509,1.42)
(1.0088953196758175,1.48)
(1.1434370771813418,1.51)
(1.115112496653863,1.51)
(1.0867879161263843,1.54)
(1.0797067709945145,1.54)
(0.8743535621702934,1.55)
(1.2567353992912569,1.59)
(1.1505182223132115,1.63)
(1.065544480730775,1.64)
(1.0018141745439477,1.64)
(1.1859239479725598,1.66)
(1.207167383368169,1.83)
(1.4833320435110873,1.93)
(1.5187377691704358,2.09)
(1.5541434948297843,2.14)
(1.9860933478738356,2.76)
(1.4337640275879995,2.17)
(1.5895492204891328,2.25)
(1.6320360912803509,2.31)
(1.5258189143023053,2.33)
(1.702847542599048,2.39)
(1.7949024293133538,2.48)
(1.844470445236442,2.56)

